{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNc4MZkT3gnUbSt5wgIv3Ui",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amara929/amara929/blob/main/Dask_Vivian.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K50H_1JXmFv-",
        "outputId": "e16a60e4-6419-4708-ff81-38cc5a8422a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/149.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m143.4/149.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.8/149.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.4/117.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install dask[complete] dask-ml --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "import dask.array as da\n",
        "from dask.distributed import Client\n",
        "\n",
        "# Initialize Dask Client (Single Machine Mode)\n",
        "client = Client()\n",
        "print(client)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mQh-9SHpDmI",
        "outputId": "2776f1e2-bcc0-4b64-bb3e-560069cc5c46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:distributed.http.proxy:To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\n",
            "INFO:distributed.scheduler:State start\n",
            "INFO:distributed.scheduler:  Scheduler at:     tcp://127.0.0.1:38047\n",
            "INFO:distributed.scheduler:  dashboard at:  http://127.0.0.1:8787/status\n",
            "INFO:distributed.scheduler:Registering Worker plugin shuffle\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:42215'\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:39409'\n",
            "INFO:distributed.scheduler:Register worker addr: tcp://127.0.0.1:41205 name: 0\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:41205\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:56160\n",
            "INFO:distributed.scheduler:Register worker addr: tcp://127.0.0.1:46345 name: 1\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:46345\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:56176\n",
            "INFO:distributed.scheduler:Receive client connection: Client-888d96c3-0ae2-11f0-80f8-0242ac1c000c\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:56192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Client: 'tcp://127.0.0.1:38047' processes=2 threads=2, memory=12.67 GiB>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create large pandas Daraframe (Simulating Big Data)\n",
        "n_rows = 1_000_000 # 1 million rows\n",
        "df = pd.DataFrame({\n",
        "    \"id\": np.arange(n_rows),\n",
        "    \"value\": np.random.randint(1, 100, n_rows),\n",
        "    \"category\": np.random.choice([\"A\", \"B\", \"C\"], n_rows)\n",
        "})\n",
        "\n",
        "# Convert Pandas Dataframe to Dask DataFrame\n",
        "ddf = dd.from_pandas(df, npartitions=10) #Split into 10 partitions"
      ],
      "metadata": {
        "id": "-2Ahf2pJpU2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows (lazy execution)\n",
        "print(ddf.head())\n",
        "\n",
        "# Get data types (metadata only, doesn't load full data)\n",
        "print(ddf.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSro2t_Ppd5K",
        "outputId": "0f5e2255-7ced-495e-8033-4007d1685105"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id  value category\n",
            "0   0     29        C\n",
            "1   1     31        C\n",
            "2   2     10        B\n",
            "3   3     64        C\n",
            "4   4     14        A\n",
            "id                    int64\n",
            "value                 int64\n",
            "category    string[pyarrow]\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows (lazy execution)\n",
        "print(ddf.head())\n",
        "\n",
        "# Get data types (metadata only, doesn't load full data)\n",
        "print(ddf.dtypes)\n",
        "\n",
        "# Perform filtering (lazy execution)\n",
        "filtered_ddf = ddf[ddf[\"value\"] > 50]\n",
        "\n",
        "# Perform aggregations (Lazy Execution)\n",
        "grouped_ddf = ddf.groupby(\"category\")[\"value\"].mean()\n",
        "\n",
        "# Compute results (Trigger execution)\n",
        "print(filtered_ddf.compute().head()) # Convert to pandafor viewing\n",
        "print(grouped_ddf.compute()) # Perform actual aggregation"
      ],
      "metadata": {
        "id": "A7eyZEAAp7oU",
        "outputId": "03e62356-975b-4693-ec4f-578fe84e6257",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id  value category\n",
            "0   0     29        C\n",
            "1   1     31        C\n",
            "2   2     10        B\n",
            "3   3     64        C\n",
            "4   4     14        A\n",
            "id                    int64\n",
            "value                 int64\n",
            "category    string[pyarrow]\n",
            "dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 23.85 MiB.\n",
            "This may cause some slowdown.\n",
            "Consider loading the data with Dask directly\n",
            " or using futures or delayed objects to embed the data into the graph without repetition.\n",
            "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id  value category\n",
            "3   3     64        C\n",
            "5   5     97        C\n",
            "6   6     89        B\n",
            "7   7     73        C\n",
            "8   8     69        A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 16.22 MiB.\n",
            "This may cause some slowdown.\n",
            "Consider loading the data with Dask directly\n",
            " or using futures or delayed objects to embed the data into the graph without repetition.\n",
            "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "category\n",
            "A    50.013463\n",
            "B    49.984288\n",
            "C    50.019296\n",
            "Name: value, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a large Dask Array (10 million elements, chunked)\n",
        "arr = da.random.random(size=(10_000_000,), chunks=(1_000_000,))\n",
        "\n",
        "# Compute mean and sum (Lazy untill '.compute()' is called)\n",
        "mean_value = arr.mean().compute()\n",
        "sum_value = arr.sum().compute()\n",
        "\n",
        "print(\"Mean:\", mean_value)\n",
        "print(\"Sum:\", sum_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmgENf29sVLr",
        "outputId": "4dc8fe63-1496-42ef-dda5-88fbfc0d88d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean: 0.5001125785718387\n",
            "Sum: 5001125.785718387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a large Dask Array (10 million elements, chunked)\n",
        "arr = da.random.random(size=(10_000_000,), chunks=(1_000_000,))\n",
        "\n",
        "# Compute mean and sum (Lazy untill '.compute()' is called)\n",
        "mean_value = arr.mean().compute()\n",
        "sum_value = arr.sum().compute()\n",
        "\n",
        "print(\"Mean:\", mean_value)\n",
        "print(\"Sum:\", sum_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhW3WcE0sttq",
        "outputId": "bc4aff08-9e77-4294-efb0-7b5ae1da8258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean: 0.499932828945583\n",
            "Sum: 4999328.28945583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dask_ml.linear_model import LinearRegression\n",
        "\n",
        "# Create a synthetic dataset\n",
        "x = da.random.random((10_000, 2), chunks=(1_000, 2))\n",
        "y = da.random.random(10_000, chunks=(1_000,))\n",
        "\n",
        "# Train a scalable Linear Regression Model\n",
        "model = LinearRegression()\n",
        "model.fit(x, y)\n",
        "\n",
        "# Predict values\n",
        "predictions = model.predict(x)\n",
        "print(predictions.compute()[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DGLJoWLs0uo",
        "outputId": "f6be8d1f-b824-410f-9a2e-b6cd4da9d66a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.49225815 0.49767491 0.4885859  0.48035649 0.49980919]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client.close()"
      ],
      "metadata": {
        "id": "MbS-CikjtG5V",
        "outputId": "771ac719-e973-42f9-f5bb-5dafdf255848",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:distributed.scheduler:Remove client Client-a28e8d5f-0ae2-11f0-80f8-0242ac1c000c\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:33808; closing.\n",
            "INFO:distributed.scheduler:Remove client Client-a28e8d5f-0ae2-11f0-80f8-0242ac1c000c\n",
            "INFO:distributed.scheduler:Close client connection: Client-a28e8d5f-0ae2-11f0-80f8-0242ac1c000c\n",
            "INFO:distributed.scheduler:Retire worker addresses (stimulus_id='retire-workers-1743063907.8471859') (0, 1)\n",
            "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:42349'. Reason: nanny-close\n",
            "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
            "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:44543'. Reason: nanny-close\n",
            "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:57062; closing.\n",
            "INFO:distributed.scheduler:Remove worker addr: tcp://127.0.0.1:39415 name: 0 (stimulus_id='handle-worker-cleanup-1743063907.8688807')\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:57068; closing.\n",
            "INFO:distributed.scheduler:Remove worker addr: tcp://127.0.0.1:33251 name: 1 (stimulus_id='handle-worker-cleanup-1743063907.8734376')\n",
            "INFO:distributed.scheduler:Lost all workers\n",
            "INFO:distributed.batched:Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:39129 remote=tcp://127.0.0.1:57068>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/distributed/batched.py\", line 115, in _background_send\n",
            "    nbytes = yield coro\n",
            "             ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 766, in run\n",
            "    value = future.result()\n",
            "            ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/distributed/comm/tcp.py\", line 262, in write\n",
            "    raise CommClosedError()\n",
            "distributed.comm.core.CommClosedError\n",
            "INFO:distributed.nanny:Nanny at 'tcp://127.0.0.1:42349' closed.\n",
            "INFO:distributed.nanny:Nanny at 'tcp://127.0.0.1:44543' closed.\n",
            "INFO:distributed.scheduler:Closing scheduler. Reason: unknown\n",
            "INFO:distributed.scheduler:Scheduler closing all comms\n"
          ]
        }
      ]
    }
  ]
}